
\chapter{基于一维卷积神经网络的三维人体姿态序列估计}
\echapter{Preface}


\section{任务分析}
\esection{}

在人们生活中的各个场景中，RGB摄像头是最为普遍且性价比较高的摄像头。尽管在三维重建等计算机视觉任务中，能够提供深度信息的RGB-D摄像头得到了一定的认可，但由于其所使用的环境严格受限且价格昂贵等因素，对于针对日常生活场景的人体姿态估计任务不具备普遍的意义。同时，在更多的场景下，针对运动中的人体，通常只具备用一个固定位姿的单目RGB摄像机拍摄的条件。而此时所采集的人体运动图像及视频，无法记录和传达各个物体以及人体的深度信息。人眼所观察到的深度信息主要来源于以下三条规律：

\begin{enumerate}
    \item “近大远小”的眼球成像规则；
    \item 空间语义信息，如遮挡、熟悉动作的普遍位移方向等；
    \item 眼睛聚焦到目标物体时，睫状肌放松和紧张的感受以及眼压的大小。
\end{enumerate}

而上述规律对神经网络来说，学习难度都较高。第一条规则依赖于目标人物的骨骼长度与学习样本的差别，第二条规则依赖于足够多样性的数据和网络自身的鲁棒性，第三条规则则不能够被现有的传感器模拟。而由于多个三维人体关节点坐标都可以投影到相同的一个二维姿态，缺失了深度信息的三维姿态恢复具有着理论上无法消除的歧义性。综上所述，对单目RGB图像及视频中的人体姿态三维关节点坐标的估计，尤其是全局三维坐标的估计具有极大的挑战。
近几年解决三维人体姿态估计的工作主要分为本文第一章中已有所介绍的两种思路，端到端式和两步式。由于二维姿态估计的发展在深度学习和良好的数据集的推动下已经较为成熟，两步式方案普遍具有着更高的效率和更好的表现。同时，虽然用相机获得直接的深度信息，或进行多目相机的多视角记录具有较小的现实意义，但视频上下文中人体运动的合理性及连贯性约束，使得帧序列之间的时序信息提取对消除歧义性有着极大的价值。本文的三维人体姿态估计任务将基于以上两个思路进行建模。


\section{具体实现}
\esection{}

在利用第三章种搭建的二维人体姿态识别网络提取出图像中的人体二维关节点坐标后，本章网络模型采取经典的两步提升操作，进一步估计关节点的三维坐标。

\subsection{时序空洞卷积模型}{}
由于二维图像提升至三维坐标本身具有歧义性，即多个三维姿态可以映射到相同的二维关键点，故而在针对视频序列进行人体姿态估计时，可以采取时序模型对相邻帧之间的时间信息进行提取。

之前的工作主要通过使用循环神经网络及长短期记忆网络进行时序信息处理。如Hossain等在2018年提出的Lee等在2018年提出的Propagating LSTM等。而卷积神经网络已经成功地在一些传统任务中建模时间信息，如神经机器翻译，语言建模，语音生成和语音估计等。故而本文采用一种基于二维关键点轨迹的一维空洞卷积处理连续帧序列中的时序信息，预测视频中的三维姿态。本文采用一个具有残余连接的完全卷积结构，它将一系列二维姿态作为输入，并通过时间维度上的卷积对它们进行转换。并利用空洞卷积，来扩展估计每一帧姿态时的时序信息的感受野，处理更大范围的上下文信息。

与依赖于循环神经网络的方法相比，它在一定的计算复杂度和参数数量具有更高的准确性、简单性和效率。首先，卷积模型支持批处理和时间维度上的并行，而循环神经网络不能随着时间的推移而并行。其次，无论序列长度如何，卷积网络的输出和输入之间的梯度路径都有固定的长度，这缓解了影响循环神经网络的消失和爆炸梯度。除此之外，卷积结构还可以对平级的时序信息有更为精确的感知，更适用于在三维姿态估计任务。

\subsection{半监督训练}{}
神经网络模型的训练需要大量标记的训练数据，而采集三维人体姿态数据集需要昂贵的运动捕捉设置和长时间的记录会话，故而数据资源的有限性给网络模型带来了极大的挑战。

类似的训练数据缺少的问题在机器翻译任务中也大量存在，机器翻译模型在训练中需要大量的双语语言成对的平行语料库，而尤其是小语种的数据极难获得。2018年Facebook针对此问题提出了无监督机器翻译模型，通过学习两种语言的共同潜在空间，实现仅使用两个单语语料库便可进行的训练。

非监督机器翻译中，从中间语言到原始语言的双向翻译应该接近恒等函数，这种循环一致性特性也同样适用于二维人体姿态提升至三维姿态和重投影的过程，故而本文的网络采取相似的方法，利用未标注的人体姿态视频对网络进行无监督训练。本文使用已有的二维人体姿态估计网络预测一个未标记视频的二维人体关节点坐标，然后提升至三维姿态，并将三维坐标映射回二维空间。所需的额外数据仅有摄像机的内在参数，而不是地面真实的二维注释或带有外部摄像机参数的多视角图像。

\section{模型结构}
\subsection{时序空洞卷积模型}{}
如图x中，卷积层为绿色的模块。网络的输入为视频每一帧中人体J个关节点的二维坐标(x,y)，即2*J个通道的数据，送入卷积核大小为W且具有C个输出通道的时序卷积模型。接着连接B个带有跳跃连接的残差块，每个残差块由一个空洞系数为D=WB的一维卷积层和一个卷积核大小为1的卷积层构成。除了最后一层卷积层外，每个卷积层后接有批标准化(BN, Batch Normalization)，ReLU线性修正单元和Dropout正则化操作。每个残差块的感受野以W进行指数增加时，保证了参数的数量仅为线性增加。卷积核的大小W及空洞系数D使得感受野以树状覆盖所有的输入帧。最终网络输出所有帧的人体三维姿态。

图x为本文网络的实际架构之一，其中B=4，w=3, c=1024，正则化因子p=0.25，总感受域为243帧。

\subsection{半监督训练}{}
本文利用未标注的视频，结合上述二维人体姿态估计模型，检测关节点坐标，用以构造反投影误差损失函数，监督模型的训练。由此构建并解决一个未标注数据自动编码解码模型。编码器为三维人体姿态估计网络，解码器为重投影操作。编码的过程为三维人体姿态估计网络从已有的关节点二维坐标进行三维姿态估计，解码的过程则将三维姿态根据根节点轨迹，相机位姿等信息投影回二维联合坐标，检查其一致性，并根据其误差对网络进行优化。

在针对人体姿态进行三维坐标估计时，通常固定人体骨骼根节点(通常为两髋骨中点)，描述其余关节点的相对坐标。而在半监督训练的重投影过程中，则需要获取人体关节点的深度轨迹即根节点的世界坐标。于是本文采用了与姿态估计相同的网络结构针对根节点轨迹进行训练，用于半监督学习的反投影计算。

由于深度信息的估计难度较高，当人体与摄像头距离较远时，其根节点世界坐标误差较大，且各关节点的深度信息区分较小，故而在训练时针对人体与摄像头的距离进行加权训练。采用针对根节点轨迹的加权平均关节点误差作为损失函数。


\section{数据及实验}
\subsection{三维人体姿态数据集}{}
Human3.6M数据集具有360万个三维人体姿势和相应的图像，共11位实验者包括6位男性和5位女性，共有17个动作场景，诸如讨论、吃饭、运动、问候等动作。用4个严格校准的相机录制高分辨率的50Hz视频。并用高速运动动作捕捉系统提供准确的关节点三维位置，像素级的24个人体部位信息。同时严格控制背景元素，提供精准的人体位置边框。在本文中，选取17个关节点信息，在(S1、S5、S6、S7、S8) 5个子集上进行训练，并用(S9、S11)2个子集作为测试集。

HumanEva-I数据集包含用三个60赫兹的摄像机记录的经过校准的视频序列(4个灰度视频和3个RGB视频)，与从运动捕捉系统获得的三维身体姿态同步。该数据库包含4名受试者执行6种常见动作(如散步、慢跑、打手势等)。给出了二维和三维姿态中计算误差的误差度量。该数据集包含训练、验证和测试集。本文采用15个关节点信息进行训练和测试。

PI-INF-3DHP 数据集，由 Max Planck Institute for Informatics 制作，是一个新发布的三维人体姿势数据集，包含 6 个7 个动作（背景为绿屏 (GS) 和无绿屏 (NoGS)），由动 (MoCap System)和 14 个 RGB 相机和 2 名受试者在室外的野外设置中执行动作。

由卡内基梅隆大学（CMU, Carnegie Mellon University）制作。使用了480个VGA摄像头，具有640 x 480的分辨率，视频帧率为25 fps，并使用了与其同步的31个HD摄像头，具有1920 x 1080分辨率，帧率为30 fps，在它们之间同步使用硬件时钟。同时，还使用了10个KinectⅡ传感器和5个DLP投影仪。采集了时长共5.5小时的65个视频序列，包含了150万个三维人体骨架信息。

\subsection{实验结果}{}
本文使用Amsgrad优化器，针对Human3.6m数据集训练80个epoch，对HumanEva数据集训练1000个epoch，并采用复制边缘帧的方法进行边缘填充。

